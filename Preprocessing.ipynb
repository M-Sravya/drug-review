{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Sravya/drug-review/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with duplicate entries\n",
        "data = {'reviews': [\"I bought this@# drug! It's AMAZING!! <html>But not sure about side-effects...</html> Highly recommend!\",\n",
        "                    \"I bought this@# drug! It's AMAZING!! <html>But not sure about side-effects...</html> Highly recommend!\",\n",
        "                    None]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "print(\"After removing duplicates:\", df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-9gc5v5teCC",
        "outputId": "c808a4f2-bc72-4797-aa1b-146ef7de7813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After removing duplicates:                                              reviews\n",
            "0  I bought this@# drug! It's AMAZING!! <html>But...\n",
            "2                                               None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling missing values (if any) with a placeholder like 'Unknown'\n",
        "df['reviews'].fillna('Data not available', inplace=True)\n",
        "print(\"After handling missing values:\", df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6dr2hRVtkma",
        "outputId": "f456577e-4689-4de1-d944-18e10a40a1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After handling missing values:                                              reviews\n",
            "0  I bought this@# drug! It's AMAZING!! <html>But...\n",
            "2                                 Data not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Sample review\n",
        "review = \"I bought this@# drug! It's AMAZING!! <html>But not sure about side-effects...</html> Highly recommend!\"\n",
        "\n",
        "# Step 1: Remove HTML tags\n",
        "def remove_html_tags(text):\n",
        "    return BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "review_no_html = remove_html_tags(review)\n",
        "\n",
        "# Step 2: Insert a new line after \"but not sure\"\n",
        "def insert_newline(text, phrase):\n",
        "    # Replace the phrase with the phrase followed by a newline\n",
        "    return text.replace(phrase, phrase + '\\n')\n",
        "\n",
        "# Specific phrase to move to a new line\n",
        "phrase = \"But not sure\"\n",
        "\n",
        "# Applying the newline insertion\n",
        "formatted_review = insert_newline(review_no_html, phrase)\n",
        "\n",
        "print(\"Removal of HTML Tags:\\n\")\n",
        "print(formatted_review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjHbLjSou84M",
        "outputId": "51fae26c-5731-4b97-8182-3103d5c322e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removal of HTML Tags:\n",
            "\n",
            "I bought this@# drug! It's AMAZING!! But not sure\n",
            " about side-effects... Highly recommend!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New step: Convert to sentence case\n",
        "# Applying the newline insertion\n",
        "phrase = \"but not sure\"\n",
        "df['reviews'] = df['reviews'].apply(lambda x: insert_newline(x, phrase))\n",
        "\n",
        "def sentence_case(text):\n",
        "    return '. '.join([sentence.capitalize() for sentence in text.split('. ')])\n",
        "\n",
        "df['reviews'] = df['reviews'].apply(sentence_case)\n",
        "print(\"\\nAfter converting to sentence case:\\n\")\n",
        "print(\"\\n\".join(df['reviews']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9lR3SLivJzz",
        "outputId": "e6c09c75-ba26-49b3-d8e9-650eb9399719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After converting to sentence case:\n",
            "\n",
            "I bought this drug! it's amazing!! but not sure\n",
            " about side-effects... Highly recommend!\n",
            "Data not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Insert a new line after \"but not sure\"\n",
        "def insert_newline(text, phrase):\n",
        "    return text.replace(phrase, phrase + '\\n').strip()\n",
        "\n",
        "phrase = \"but not sure\"\n",
        "df['reviews'] = df['reviews'].apply(lambda x: insert_newline(x, phrase))\n",
        "\n",
        "# Step 3: Remove special characters\n",
        "def remove_special_characters(text):\n",
        "    # Updated regex pattern\n",
        "    cleaned_text = re.sub(r'[&,*@$\\/|\\\\:;<>,#^]', '', text)\n",
        "    # Remove multiple new lines and trim extra spaces\n",
        "    cleaned_text = re.sub(r'\\n+', '\\n', cleaned_text).strip()\n",
        "    return cleaned_text\n",
        "\n",
        "df['reviews'] = df['reviews'].apply(remove_special_characters)\n",
        "# Output the cleaned reviews\n",
        "print(\"\\nAfter removing special characters:\")\n",
        "print(\"\\n\".join(df['reviews']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q14aNLb3uTd0",
        "outputId": "0bd08d76-c800-4885-8c79-9e8dfc199e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After removing special characters:\n",
            "I bought this drug! it's amazing!! but not sure\n",
            " about side-effects... Highly recommend!\n",
            "Data not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Ensure NLTK resources are downloaded\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZqunmYu2Cb3",
        "outputId": "a43f6b14-32dc-43e7-fb17-6cec92574b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Insert a new line after \"but not sure\"\n",
        "def insert_newline(text, phrase):\n",
        "    return text.replace(phrase, phrase + '\\n').strip()\n",
        "\n",
        "phrase = \"but not sure\"\n",
        "df['reviews'] = df['reviews'].apply(lambda x: insert_newline(x, phrase))\n",
        "# Step 5: Tokenization\n",
        "\n",
        "def tokenize(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "df['tokens'] = df['reviews'].apply(tokenize)\n",
        "\n",
        "# Output the cleaned reviews and tokens\n",
        "print(\"\\nAfter removing special characters and tokenizing:\\n\")\n",
        "print(df[['reviews', 'tokens']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLyALjvsvUpI",
        "outputId": "27e2f452-f267-496c-e47a-ae02d09e22b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After removing special characters and tokenizing:\n",
            "\n",
            "                                             reviews  \\\n",
            "0  I bought this drug! it's amazing!! but not sur...   \n",
            "2                                 Data not available   \n",
            "\n",
            "                                              tokens  \n",
            "0  [I, bought, this, drug, !, it, 's, amazing, !,...  \n",
            "2                             [Data, not, available]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# Step 6: Remove stop words\n",
        "nltk.download('stopwords')\n",
        "nltk_stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lES7EKNEwBz6",
        "outputId": "50782398-dbbb-4239-c347-320e6aeacf06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After removing stop words:\n",
            "\n",
            "['I', 'bought', 'drug!', 'amazing!!', 'sure', 'side-effects...', 'Highly', 'recommend!']\n",
            "['Data', 'available']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Lemmatization\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_words(tokens):\n",
        "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "df['tokens'] = df['tokens'].apply(lemmatize_words)\n",
        "print(\"\\nAfter lemmatization:\\n\")\n",
        "print(\"\\n\".join([str(tokens) for tokens in df['tokens']]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ-s04XvwEwF",
        "outputId": "738a3c8d-92bf-45d9-d989-82f37981742b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After lemmatization:\n",
            "\n",
            "['I', 'bought', 'drug!', 'amazing!!', 'sure', 'side-effects...', 'Highly', 'recommend!']\n",
            "['Data', 'available']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Joining tokens back into a sentence\n",
        "df['processed_review'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
        "print(\"\\nAfter joining words back:\\n\")\n",
        "print(\"\\n\".join(df['processed_review']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9rc1WWFwWiW",
        "outputId": "b69b9fed-71ac-4552-f0ad-bc24dc0b57db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After joining words back:\n",
            "\n",
            "I bought drug! amazing!! sure side-effects... Highly recommend!\n",
            "Data available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Padding (assuming max length of 10)\n",
        "# Step 2: Insert a new line after a specific phrase\n",
        "def insert_newline(text, phrase):\n",
        "    # Replace the phrase with the phrase followed by a newline and remove extra newlines\n",
        "    text_with_newline = text.replace(phrase, phrase + '\\n').strip()\n",
        "    # Remove multiple new lines and trim extra spaces\n",
        "    return re.sub(r'\\n+', '\\n', text_with_newline)\n",
        "\n",
        "phrase = \"but not sure\"\n",
        "df['reviews'] = df['reviews'].apply(lambda x: insert_newline(x, phrase))\n",
        "max_length = 10\n",
        "\n",
        "def pad_or_truncate(tokens, max_length):\n",
        "    return tokens[:max_length] + ['<PAD>'] * (max_length - len(tokens)) if len(tokens) < max_length else tokens[:max_length]\n",
        "\n",
        "df['padded_review'] = df['tokens'].apply(lambda x: pad_or_truncate(x, max_length))\n",
        "print(\"\\nAfter padding:\\n\")\n",
        "print(\"\\n\".join([str(tokens) for tokens in df['padded_review']]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5ofXbCNwZX2",
        "outputId": "5d1a60e8-223d-4553-c135-7357b27ded90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After padding:\n",
            "\n",
            "['I', 'bought', 'this', 'drug', '!', 'it', \"'s\", 'amazing', '!', '!']\n",
            "['Data', 'not', 'available', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Preprocessed reviews\n",
        "preprocessed_reviews = [\n",
        "    \"I bought drug amazing drugscompany sure sideeffects highly recommend\",\n",
        "    \"Sideeffects terrible recommended\",\n",
        "    \"Loved result highly effective drug expensive\",\n",
        "    \"Drug affordable sure safe\",\n",
        "    \"Product review better\"\n",
        "]\n",
        "\n",
        "# Corresponding sentiments for the preprocessed reviews\n",
        "sentiments = ['Positive', 'Negative', 'Positive', 'Neutral', 'Neutral']\n",
        "\n",
        "# Create a DataFrame with the preprocessed reviews and sentiments\n",
        "df_preprocessed = pd.DataFrame({\n",
        "    'processed_review': preprocessed_reviews,\n",
        "    'review_sentiment': sentiments\n",
        "})\n",
        "\n",
        "# Apply Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the sentiment labels\n",
        "df_preprocessed['encoded_sentiment'] = label_encoder.fit_transform(df_preprocessed['review_sentiment'])\n",
        "\n",
        "# Display the DataFrame with encoded sentiments\n",
        "print(\"\\nDataFrame with encoded sentiments:\\n\", df_preprocessed[['processed_review', 'review_sentiment', 'encoded_sentiment']])\n",
        "\n",
        "# Display mapping of labels\n",
        "print(\"\\nMapping of Sentiments:\\n\")\n",
        "for sentiment, code in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
        "    print(f\"{sentiment}: {code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAXOrzVWwdKM",
        "outputId": "fe1d4294-afc6-4f22-8e4f-476af0920656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with encoded sentiments:\n",
            "                                     processed_review review_sentiment  \\\n",
            "0  I bought drug amazing drugscompany sure sideef...         Positive   \n",
            "1                   Sideeffects terrible recommended         Negative   \n",
            "2       Loved result highly effective drug expensive         Positive   \n",
            "3                          Drug affordable sure safe          Neutral   \n",
            "4                              Product review better          Neutral   \n",
            "\n",
            "   encoded_sentiment  \n",
            "0                  2  \n",
            "1                  0  \n",
            "2                  2  \n",
            "3                  1  \n",
            "4                  1  \n",
            "\n",
            "Mapping of Sentiments:\n",
            "\n",
            "Negative: 0\n",
            "Neutral: 1\n",
            "Positive: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WPHTRfXoxVez"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}